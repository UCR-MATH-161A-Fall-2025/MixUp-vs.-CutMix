{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raFweHtx8RcE"
      },
      "outputs": [],
      "source": [
        "# ==========================================================\n",
        "#CIFAR-10 MixUp vs CutMix with AdamW\n",
        "# ==========================================================\n",
        "\n",
        "# ==========================================================\n",
        "# Setup — configs, utils, model, MixUp/CutMix (no local imports)\n",
        "# ==========================================================\n",
        "import os, csv, random, numpy as np, torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "# ---------- configs ----------\n",
        "def _merge(a, b):\n",
        "    out = dict(a)\n",
        "    for k, v in b.items():\n",
        "        if isinstance(v, dict) and isinstance(out.get(k), dict):\n",
        "            out[k] = _merge(out[k], v)\n",
        "        else:\n",
        "            out[k] = v\n",
        "    return out\n",
        "\n",
        "BASE = {\n",
        "    \"seed\": 42,\n",
        "    \"epochs\": 100,\n",
        "    \"batch_size\": 128,\n",
        "    \"num_workers\": 2,  # set 2 for Colab/low-core systems to avoid worker warning\n",
        "    \"amp\": True,\n",
        "    \"label_smoothing\": 0.0,\n",
        "    \"optimizer\": {\"name\": \"adamw\", \"lr\": 5e-4, \"weight_decay\": 0.02, \"betas\": (0.9, 0.999), \"eps\": 1e-8},\n",
        "    \"scheduler\": {\"warmup_epochs\": 5},\n",
        "    \"model\": {\"name\": \"resnet18_cifar\"},\n",
        "    \"data\": {\n",
        "        \"root\": \"./data\",\n",
        "        \"mean\": (0.4914, 0.4822, 0.4465),\n",
        "        \"std\":  (0.2470, 0.2435, 0.2616),\n",
        "    },\n",
        "    \"augment_mode\": \"off\",   # off | mixup | cutmix\n",
        "    \"mixup_alpha\": 0.0,\n",
        "    \"cutmix_alpha\": 0.0,\n",
        "    \"save_dir\": \"results/run\",\n",
        "}\n",
        "MIXUP  = {\"augment_mode\": \"mixup\",  \"mixup_alpha\": 0.4, \"save_dir\": \"results/mixup\"}\n",
        "CUTMIX = {\"augment_mode\": \"cutmix\", \"cutmix_alpha\": 1.0, \"save_dir\": \"results/cutmix\"}\n",
        "\n",
        "PROFILES = {\"base\": BASE, \"mixup\": _merge(BASE, MIXUP), \"cutmix\": _merge(BASE, CUTMIX)}\n",
        "\n",
        "def get_config(profile: str, overrides: dict | None = None):\n",
        "    if profile not in PROFILES:\n",
        "        raise ValueError(f\"unknown profile: {profile}\")\n",
        "    cfg = dict(PROFILES[profile])\n",
        "    if overrides:\n",
        "        cfg = _merge(cfg, overrides)\n",
        "    return cfg\n",
        "\n",
        "# ---------- io + reproducibility ----------\n",
        "def ensure_dir(d): os.makedirs(d, exist_ok=True)\n",
        "def save_ckpt(state, path): torch.save(state, path)\n",
        "def csv_logger(path):\n",
        "    f = open(path, \"w\", newline=\"\")\n",
        "    w = csv.DictWriter(f, fieldnames=[\"epoch\",\"train_loss\",\"val_loss\",\"val_acc\"])\n",
        "    w.writeheader()\n",
        "    return f, w\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# ---------- optimizer + scheduler ----------\n",
        "def build_optimizer(model, cfg):\n",
        "    opt = cfg[\"optimizer\"]\n",
        "    if opt[\"name\"].lower() != \"adamw\":\n",
        "        raise ValueError(\"This setup uses AdamW for both MixUp and CutMix.\")\n",
        "    return AdamW(model.parameters(), lr=opt[\"lr\"], weight_decay=opt[\"weight_decay\"],\n",
        "                 betas=opt.get(\"betas\", (0.9,0.999)), eps=opt.get(\"eps\", 1e-8))\n",
        "\n",
        "def build_warmup_cosine(optimizer, steps_per_epoch: int, epochs: int, warmup_epochs: int):\n",
        "    warmup_iters = max(1, warmup_epochs * steps_per_epoch)\n",
        "    total_iters  = max(1, epochs * steps_per_epoch)\n",
        "    cosine_iters = max(1, total_iters - warmup_iters)\n",
        "    warmup = LinearLR(optimizer, start_factor=1e-3, end_factor=1.0, total_iters=warmup_iters)\n",
        "    cosine = CosineAnnealingLR(optimizer, T_max=cosine_iters)\n",
        "    return SequentialLR(optimizer, [warmup, cosine], milestones=[warmup_iters])\n",
        "\n",
        "# ---------- model ----------\n",
        "def build_model(name: str, num_classes=10):\n",
        "    if name != \"resnet18_cifar\":\n",
        "        raise ValueError(f\"unsupported model: {name}\")\n",
        "    m = resnet18(weights=None, num_classes=num_classes)\n",
        "    m.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    m.maxpool = nn.Identity()\n",
        "    return m\n",
        "\n",
        "# ---------- MixUp / CutMix ----------\n",
        "def mixup_data(x, y, alpha: float):\n",
        "    lam = torch.distributions.Beta(alpha, alpha).sample().item() if alpha and alpha > 0 else 1.0\n",
        "    idx = torch.randperm(x.size(0), device=x.device)\n",
        "    return lam * x + (1 - lam) * x[idx], y, y[idx], lam\n",
        "\n",
        "def mixup_criterion(crit, pred, y_a, y_b, lam):\n",
        "    return lam * crit(pred, y_a) + (1 - lam) * crit(pred, y_b)\n",
        "\n",
        "def _rand_bbox(W, H, lam):\n",
        "    r = (1 - lam) ** 0.5\n",
        "    cw, ch = int(W*r), int(H*r)\n",
        "    cx, cy = np.random.randint(W), np.random.randint(H)\n",
        "    x1, y1 = np.clip(cx - cw//2, 0, W), np.clip(cy - ch//2, 0, H)\n",
        "    x2, y2 = np.clip(cx + cw//2, 0, W), np.clip(cy + ch//2, 0, H)\n",
        "    return x1, y1, x2, y2\n",
        "\n",
        "def cutmix_data(x, y, alpha: float):\n",
        "    lam = torch.distributions.Beta(alpha, alpha).sample().item() if alpha and alpha > 0 else 1.0\n",
        "    bs, _, H, W = x.size()\n",
        "    idx = torch.randperm(bs, device=x.device)\n",
        "    x1, y1, x2, y2 = _rand_bbox(W, H, lam)\n",
        "    x[:, :, y1:y2, x1:x2] = x[idx, :, y1:y2, x1:x2]\n",
        "    lam = 1 - ((x2 - x1) * (y2 - y1)) / (W * H)  # exact area ratio\n",
        "    return x, y, y[idx], lam\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# CIFAR10 MixUp vs CutMix + AdamW (Notebook Safe\n",
        "# Wire everything together: data, model, optimizer/scheduler, augmentation, AMP, training loop, validation, and logging.\n",
        "# Per-iteration stepping keeps LR in sync with updates; AMP speeds up on modern GPUs with low complexity.\n",
        "# ==========================================================\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ------------------ args (notebook + CLI compatible) ------------------\n",
        "def parse_args(argv=None):\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--profile\", choices=[\"base\",\"mixup\",\"cutmix\"],\n",
        "                    default=os.environ.get(\"PROFILE\",\"mixup\"),\n",
        "                    help=\"experiment profile; default='mixup' (override with PROFILE env var)\")\n",
        "    ap.add_argument(\"--save_dir\", type=str, default=None)\n",
        "    ap.add_argument(\"--epochs\", type=int, default=None)\n",
        "    ap.add_argument(\"--batch_size\", type=int, default=None)\n",
        "    ap.add_argument(\"--lr\", type=float, default=None)\n",
        "    ap.add_argument(\"--weight_decay\", type=float, default=None)\n",
        "    ap.add_argument(\"--mixup_alpha\", type=float, default=None)\n",
        "    ap.add_argument(\"--cutmix_alpha\", type=float, default=None)\n",
        "    if argv is None:  # ignore IPython/Colab argv\n",
        "        argv = []\n",
        "    return ap.parse_args(argv)\n",
        "\n",
        "# ------------------ transforms ------------------\n",
        "def build_transforms(mean, std):\n",
        "    train_tfms = T.Compose([\n",
        "        T.RandomCrop(32, padding=4),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean, std)\n",
        "    ])\n",
        "    test_tfms = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean, std)\n",
        "    ])\n",
        "    return train_tfms, test_tfms\n",
        "\n",
        "# ------------------ eval ------------------\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    total = correct = 0\n",
        "    loss_sum = 0.0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        loss_sum += F.cross_entropy(logits, y).item() * y.size(0)\n",
        "        pred = logits.argmax(1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return loss_sum / total, correct / total\n",
        "\n",
        "# ------------------ train one epoch ------------------\n",
        "def train_one_epoch(model, loader, optimizer, scaler, device, criterion,\n",
        "                    scheduler, augment_mode, mixup_alpha, cutmix_alpha, use_amp):\n",
        "    model.train()\n",
        "    total = 0\n",
        "    loss_sum = 0.0\n",
        "    for x, y in tqdm(loader, leave=False, desc=\"train\"):\n",
        "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "\n",
        "        if augment_mode == \"mixup\":\n",
        "            x, ya, yb, lam = mixup_data(x, y, mixup_alpha)\n",
        "            loss_fn = lambda logits: mixup_criterion(criterion, logits, ya, yb, lam)\n",
        "        elif augment_mode == \"cutmix\":\n",
        "            x, ya, yb, lam = cutmix_data(x, y, cutmix_alpha)\n",
        "            loss_fn = lambda logits: mixup_criterion(criterion, logits, ya, yb, lam)\n",
        "        else:\n",
        "            loss_fn = lambda logits: criterion(logits, y)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "            logits = model(x)\n",
        "            loss = loss_fn(logits)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        bs = y.size(0)\n",
        "        total += bs\n",
        "        loss_sum += loss.item() * bs\n",
        "    return loss_sum / total\n",
        "\n",
        "# ------------------ main ------------------\n",
        "def main():\n",
        "    args = parse_args()\n",
        "\n",
        "    # overrides from args\n",
        "    overrides = {}\n",
        "    if args.save_dir is not None: overrides[\"save_dir\"] = args.save_dir\n",
        "    if args.epochs is not None: overrides[\"epochs\"] = args.epochs\n",
        "    if args.batch_size is not None: overrides[\"batch_size\"] = args.batch_size\n",
        "    if args.lr is not None: overrides.setdefault(\"optimizer\", {})[\"lr\"] = args.lr\n",
        "    if args.weight_decay is not None: overrides.setdefault(\"optimizer\", {})[\"weight_decay\"] = args.weight_decay\n",
        "    if args.mixup_alpha is not None: overrides[\"mixup_alpha\"] = args.mixup_alpha\n",
        "    if args.cutmix_alpha is not None: overrides[\"cutmix_alpha\"] = args.cutmix_alpha\n",
        "\n",
        "    cfg = get_config(args.profile, overrides)\n",
        "    set_seed(cfg[\"seed\"])\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    ensure_dir(cfg[\"save_dir\"])\n",
        "    ckpt_dir = os.path.join(cfg[\"save_dir\"], \"ckpts\")\n",
        "    ensure_dir(ckpt_dir)\n",
        "    log_f, writer = csv_logger(os.path.join(cfg[\"save_dir\"], \"metrics.csv\"))\n",
        "\n",
        "    mean, std = cfg[\"data\"][\"mean\"], cfg[\"data\"][\"std\"]\n",
        "    train_tfms, test_tfms = build_transforms(mean, std)\n",
        "\n",
        "    # CIFAR-10 datasets\n",
        "    train_set = torchvision.datasets.CIFAR10(root=cfg[\"data\"][\"root\"], train=True,  download=True, transform=train_tfms)\n",
        "    test_set  = torchvision.datasets.CIFAR10(root=cfg[\"data\"][\"root\"], train=False, download=True, transform=test_tfms)\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=cfg[\"batch_size\"], shuffle=True,\n",
        "                              num_workers=cfg[\"num_workers\"], pin_memory=True, drop_last=True)\n",
        "    test_loader  = DataLoader(test_set,  batch_size=cfg[\"batch_size\"], shuffle=False,\n",
        "                              num_workers=cfg[\"num_workers\"], pin_memory=True)\n",
        "\n",
        "    # model / opt / loss / AMP / scheduler\n",
        "    model = build_model(cfg[\"model\"][\"name\"], num_classes=10).to(device)\n",
        "    optimizer = build_optimizer(model, cfg)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=cfg.get(\"label_smoothing\", 0.0))\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=cfg[\"amp\"])\n",
        "\n",
        "    steps_per_epoch = len(train_loader)\n",
        "    scheduler = build_warmup_cosine(optimizer, steps_per_epoch, cfg[\"epochs\"], cfg[\"scheduler\"][\"warmup_epochs\"])\n",
        "\n",
        "    augment_mode = cfg.get(\"augment_mode\", \"off\")\n",
        "    mixup_alpha  = cfg.get(\"mixup_alpha\", 0.0)\n",
        "    cutmix_alpha = cfg.get(\"cutmix_alpha\", 0.0)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(cfg[\"epochs\"]):\n",
        "        tr_loss = train_one_epoch(model, train_loader, optimizer, scaler, device, criterion, scheduler,\n",
        "                                  augment_mode, mixup_alpha, cutmix_alpha, cfg[\"amp\"])\n",
        "        va_loss, va_acc = evaluate(model, test_loader, device)\n",
        "        writer.writerow({\"epoch\": epoch, \"train_loss\": tr_loss, \"val_loss\": va_loss, \"val_acc\": va_acc})\n",
        "        if va_acc > best_acc:\n",
        "            best_acc = va_acc\n",
        "            save_ckpt({\"epoch\": epoch, \"model\": model.state_dict(), \"best_acc\": best_acc},\n",
        "                      os.path.join(ckpt_dir, \"best.pth\"))\n",
        "        print(f\"epoch {epoch+1}/{cfg['epochs']} | train {tr_loss:.4f} | val {va_loss:.4f} | acc {va_acc*100:.2f}%\")\n",
        "\n",
        "    log_f.close()\n",
        "\n",
        "# entry\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "RbqDCkeR8nsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# eval.py — Summarize MixUp vs CutMix results (Notebook Table Output)\n",
        "# ==========================================================\n",
        "import os, glob, pandas as pd\n",
        "\n",
        "def load_runs(root):\n",
        "    runs = []\n",
        "    for csv_path in glob.glob(os.path.join(root, \"**\", \"metrics.csv\"), recursive=True):\n",
        "        try:\n",
        "            df = pd.read_csv(csv_path)\n",
        "        except Exception:\n",
        "            continue\n",
        "        if len(df) == 0:\n",
        "            continue\n",
        "        runs.append({\n",
        "            \"run\": os.path.dirname(csv_path),\n",
        "            \"final_acc\": float(df[\"val_acc\"].iloc[-1])\n",
        "        })\n",
        "    return pd.DataFrame(runs)\n",
        "\n",
        "def summarize(roots):\n",
        "    parts = []\n",
        "    for r in roots:\n",
        "        tag = os.path.basename(r.rstrip(\"/\"))\n",
        "        df = load_runs(r)\n",
        "        if df.empty:\n",
        "            print(f\"no runs found under {r}\")\n",
        "            continue\n",
        "        df[\"tag\"] = tag\n",
        "        parts.append(df)\n",
        "\n",
        "    if not parts:\n",
        "        print(\"no runs to summarize\")\n",
        "        return None\n",
        "\n",
        "    out = pd.concat(parts, ignore_index=True)\n",
        "    summary = out.groupby(\"tag\")[\"final_acc\"].agg([\"mean\", \"std\", \"count\"]).reset_index()\n",
        "    display(summary.style.set_caption(\"MixUp vs CutMix Summary\").format({\"mean\": \"{:.4f}\", \"std\": \"{:.4f}\"}))\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "yLvz1tRP89Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize([\"results/mixup\", \"results/cutmix\"])\n"
      ],
      "metadata": {
        "id": "j5PBmhhIQFPw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}